---
title: "Topic Modeling with Russian Novels and Songs"
author: "David Teuscher"
date: "2023-06-17"
slug: "topic-modeling-with-russian"
categories: []
tags:
- Russian
- NLP
- topic modeling
- Python
subtitle: ''
summary: Using topic modeling to explore trends in the writing of Dostoevsky and the
  song lyrics of Viktor Tsoi
authors: []
lastmod: "2023-06-17T13:29:38-06:00"
featured: no
fig_caption: yes
image:
  caption: ''
  focal_point: ''
  preview_only: yes
projects: []
---



<div id="background-of-project" class="section level2">
<h2>Background of Project</h2>
<p>As of writing this post, I have studied Russian for approximately 9 years. I enjoyed studying Russian enough that I also studied it in college in addition to statistics. Since I enjoy both the Russian language and statistics, I wanted to find a way to combine the two of them together. Natural language processing (NLP) is one way that I am able to combine the two interests where computers and algorithms are used to analyze and attempt to find meaning from human language.</p>
<p>In a linguistics class I took in college, we were briefly introduced to topic modeling. Topic modeling is a form of unsupervised machine learning that takes a large collection of documents and attempts to find relevant topics or clusters. In this class, we were only introduced to the general idea of it, but since I have a statistics background, I spent some time learning about topic modeling. I won’t outline much of the statistical details here because there are more than enough resources on the internet already that outline the statistics behind topic modeling.</p>
<p>Since I found the idea and details behind topic modeling interesting, I decided to make that the center of this project. When deciding what kind of text I wanted to analyze, I decided to examine texts from two unique areas: literature and music. I really enjoy Dostoevsky’s works of literature with Crime and Punishment being one of my favorite novels of all-time, so I wanted to analyze his works. When deciding what type of music to examine, I eventually decided to collect the lyrics for songs written by Viktor Tsoi, who was one of the more influential musicians in the Soviet Union and his music is still popular among people in Russia.</p>
<p>The final idea for this project was inspired by <a href="https://medium.com/the-die-is-forecast/topic-modeling-as-osint-exploring-russian-presidential-speech-topics-over-time-ad6018286d37">this post</a>, which outlined looking at topics discovered from topic modeling over time and examining which themes were more prevalent over the course of time. I thought this would be interesting to explore, especially because Dostoevsky’s writing evolved and changed over time and I was interested if I could discover topics or groups that could show that.</p>
<p>The rest of this post will outline where the data was collected from, how the text was preprocessed for topic modeling, the process of determining the topics, and finally examining the prevalence of these topics over time.</p>
</div>
<div id="data-collectionweb-scraping" class="section level2">
<h2>Data Collection/Web Scraping</h2>
<p>I needed data from different sources for this project. I needed to find somewhere where I could get the text for songs by Viktor Tsoi as well as the text from Dostoevsky’s published works. I was able to find the data from two different sources.</p>
<p>For Viktor Tsoi’s songs, I ended up needing to webscrape the lyrcis for songs from the internet. I found a <a href="https://lyric-text.ru/viktor-tsoy/">website</a> that contained links to the songs and their lyrics from Viktor Tsoi. I decided to use BeautifulSoup to webscrape, so I ended up copying the URLs for the four pages of songs. The code below outlines the process of getting the links for each song and saving the song title as well.</p>
<pre class="python"><code># Create empty list for links and song title
links = []
song_title = []
# Loop through the four URLs to scrape from
for url in urls:
    # Specify header information related to your computer
    headers = {
        #header_information for your computer}
    # Make a request to the web page
    response = requests.get(url, headers=headers)
    # Parse the HTML content on the page
    soup = bs(response.content, &quot;html.parser&quot;)
    # Find all the div tags with the specific class
    paragraphs = soup.find_all(&quot;div&quot;, {&#39;class&#39;: &#39;content_box&#39;})
    # Loop through each found div tag
    for paragraph in paragraphs:
        # Pull all the anchors out
        anchors = paragraph.find_all(&#39;a&#39;)
        # Try to take the href from the anchor tag if possible
        for anchor in anchors:
            try:
                links.append(anchor.attrs[&#39;href&#39;])
                song_title.append(anchor.get_text())
            # print that the anchor is skipped if there is a KeyError resulting from no href attribute
            except KeyError:
                print(&quot;skipping this anchor because it doesn&#39;t have an href attribute&quot;)</code></pre>
<p>After I extracted the links for each song, I looped through each link and extracted the song lyrics and saved the title and lyrics to a <code>.txt</code> file to be used later. In order to get the song lyrics, I only needed to extracted the paragraph element from the main div that contained the content on the page. The code for scraping the lyrics and saving them to a file are provided before:</p>
<pre class="python"><code>with open(f&quot;songs.txt&quot;, mode=&#39;w&#39;) as outfile:
    # Write a header for the file
    outfile.write(&quot;Title&quot; + &quot;\t&quot; + &quot; Lyrics&quot; + &#39;\n&#39;)
    # Loop through the links
    for i in range(len(links)):
        # Get the HTML content
        response = requests.get(links[i], headers=headers)
        # Parse the HTML content on the page
        soup = bs(response.content, &quot;html.parser&quot;)
        # Find all the divs with the specific class and then the paragraph inside
        paragraphs = soup.find(&#39;div&#39;, {&#39;class&#39;: &#39;content_box&#39;}).find(&#39;p&#39;)
        # Write out to text file if there is text
        try:
            outfile.write(song_title[i] + &quot;\t&quot; + paragraphs.get_text(strip=True) + &#39;\n&#39;)
            print(f&#39;Writing {song_title[i]}&#39;)
        except:
            print(&quot;No text. Moving to next link&quot;)
            continue</code></pre>
<p>Finding the texts of Dostoevsky’s works was a lot easier than getting the song lyrics I needed. There was a <a href="https://www.kaggle.com/datasets/d0rj3228/russian-literature/data">Kaggle dataset</a> that had text files for 34 works of literature by Dostoevsky. This didn’t include everything that Doestoevsky ever wrote, but it did include his major works, so I thought that it was enough for this project.</p>
<p>The Kaggle dataset also included a file that had the year the book was written, which was also need for determining how the topics changed over time. I had to manually create a file that had the year that each song was written. I used Wikipedia to get the years when songs were written.</p>
<p>Once I had collected all of the data, I was able to begin working with the data. There was a decent amount of preprocessing that needed to be done before I could try topic modeling.</p>
</div>
<div id="text-preprocessing" class="section level2">
<h2>Text Preprocessing</h2>
<p>There were a number of steps that I took to preprocess the text for analyzing and topic modeling. I’ll walk through the general preprocessing steps that I took and then I will highlight a few specific details that relate to this specific project.</p>
<p>The general steps that I took to clean up the texts for topic modeling include:</p>
<ul>
<li><p>Removing any punctuation or white space</p></li>
<li><p>Removing stopwords</p></li>
<li><p>Split the text into words</p></li>
<li><p>Lemmatization of words</p></li>
</ul>
<p>I wrote a function that is shown below to perform all of the preprocessing steps.</p>
<pre class="python"><code>russian_stopwords = stopwords.words(&quot;russian&quot;) + [&quot;твой&quot;, &quot;наш&quot;, &quot;это&quot;, &quot;--&quot;, &quot;\&quot;&quot;, &quot;–&quot;, &quot;—&quot;,
                                                  &quot;…&quot;, &quot;,&quot;, &quot;...&quot;, &quot;…&quot;, &quot;»&quot;, &quot;«&quot;, &quot;-&quot;, &quot;м&quot;, &quot;когда&quot;, &quot;э&quot;, &quot;24&quot;, &quot;то&quot;, &quot;припев&quot;, &quot;то&quot;, &quot;весь&quot;, &quot;:&quot;, &quot;эй&quot;, &quot;кто&quot;, &quot;свой&quot;]


# Preprocess function for the text
def preprocess_text(text):
    tokens = mystem.lemmatize(text.lower())
    tokens = [token for token in tokens if token not in russian_stopwords \
              and token != &quot; &quot; \
              and token.strip() not in string.punctuation]

    text = &quot; &quot;.join(tokens).replace(&quot;,&quot;, &quot; &quot;).replace(&quot;«&quot;, &quot; &quot;).replace(&quot;–&quot;, &quot; &quot;).replace(&quot;--&quot;, &quot; &quot;).replace(&quot;—&quot;, &quot; &quot;).replace(&quot;-&quot;, &quot; &quot;).replace(&quot;»&quot;, &quot; &quot;).replace(&quot;\&quot;&quot;, &quot; &quot;).replace(&quot;::&quot;, &quot; &quot;)

    return text</code></pre>
<p>One difference with preprocessing is that I was working with Russian texts, which have a different grammatical structure. Russian uses grammatical cases where nouns and adjectives change endings depending on their placement and meaning in a sentence. As a result of this, a single noun can have multiple different endings depending on the sentence, but has more or less the same meaning. Using lemmatization to break down these words to their original base word, instead of just to a stem using stemming, is extremely helpful for getting meaning out of Russian texts. I ended up using <code>pymystem3</code>, which uses Yandex’s morphological analyzer, MyStem.</p>
<p>The other nuance with preprocessing is that although NLTK has stopwords for Russian, it only has a small number of potential stopwords. Initially, I looked at the topic using only the Russian stopwords from NLTK, but found a lot of additional words that would be considered stopwords and had minimal meaning when examinig topics. As a result, I manually added additional words to the stopwords that I removed.</p>
<p>After the text for both the songs and the novels were cleaned, I created a corpora for the songs and books separately. With each corpora, I also calculated the document term matrix to be used for topic modeling with Latent Dirichlet Allocation (LDA).</p>
</div>
<div id="topic-modeling-using-lda" class="section level2">
<h2>Topic Modeling using LDA</h2>
</div>
<div id="topics-over-time" class="section level2">
<h2>Topics over Time</h2>
</div>
<div id="recap" class="section level2">
<h2>Recap</h2>
</div>
